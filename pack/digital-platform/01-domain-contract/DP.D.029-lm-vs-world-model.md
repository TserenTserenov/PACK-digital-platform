---
id: DP.D.029
name: "Language Model \u2260 World Model"
type: distinction
status: active
summary: "LLM = пассивные знания о мире из текстов (кабинетный учёный). World Model = активная модель, обновляемая из взаимодействия с реальностью (инженер). Критерий: замыкает ли система цикл действие-измерение-обновление"
created: 2026-02-19
edition: "2026-02"
source: "Левенчук, Как поумнеть человеку или роботу, 19 фев 2026"
trust:
  F: 4
  G: external
  R: 0.7
related:
  extends: [DP.FM.003, DP.D.025]
  references: [DP.SOTA.013, DP.M.007]
  see_also: [DP.FM.005]
tags: [llm, world-model, distinction, embodied, cabinet-scholar]
---

# Language Model (LLM) ≠ World Model

## Различение

| Language Model (LLM) | World Model |
|----------------------|-------------|
| Пассивные знания о мире, выученные из текстов | Активная модель, обновляемая из взаимодействия с реальностью |
| «Кабинетный учёный» — доступ к миру через пользователя | «Инженер» — замеряет, зондирует, обновляет представления |
| Данные на входе → данные на выходе | Действие → измерение → обновление состояния |
| Не отслеживает дрейф состояния мира | Отслеживает невязку ожидания и реальности |
| Улучшение = самосогласованность (непротиворечивость) | Улучшение = близость предсказаний к миру |
| RAG/tools/retrieval расширяют, но не замыкают цикл | Цикл замкнут архитектурно |

## Почему важно

Без этого различения возникает иллюзия: «дадим LLM больше контекста / tools / RAG — и он станет world model». Нет. RAG расширяет кабинет, но не выводит из него. Для world model нужен архитектурный элемент: хранение состояния + прогноз + невязка + обновление (DP.SOTA.013).

AI-агент на LLM без measurement loop деградирует в «самосогласованный текст» (DP.FM.005): внутренние согласования улучшаются, но близость к реальности не растёт.

## Тест

1. Замыкает ли система цикл действие → измерение → обновление? **Нет** → LLM-режим
2. Хранит ли система состояние мира между циклами? **Нет** → LLM-режим
3. Превращает ли ошибку прогноза в обновление представлений? **Нет** → LLM-режим

Все три «да» → world model-режим. Частичные «да» → гибрид (типичный случай для экзокортекса с Capture-to-Pack).

## Экзокортекс: где мы сейчас

Экзокортекс = **гибрид** (LLM + частичные measurement loops):

| Компонент | LLM или WM? | Почему |
|-----------|-------------|--------|
| AI-консультант (бот) | LLM | Нет хранения состояния между сессиями (кроме user_profile) |
| Capture-to-Pack | proto-WM | Фиксирует наблюдения → обновляет Pack (знания) |
| Стратег (week-review) | proto-WM | Сравнивает план/факт → обновляет приоритеты |
| Unsatisfied-questions | proto-WM | Сигнал невязки: пользователь не удовлетворён → знание неточно |
| Code-scan (TODO/FIXME) | proto-WM | Автоматическое обнаружение расхождения код/намерение |

> Вектор развития: усиливать measurement loops (DP.M.007), а не увеличивать мощность LLM.
